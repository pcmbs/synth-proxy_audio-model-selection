encoder: 
  _target_: models.openl3.torchopenl3_wrapper.TorchOpenL3Wrapper
  input_repr: linear # \in {linear, mel128, mel256}
  content_type: env # \in {music, env}
  embedding_size: 6144 # \in {512, 6144}
  hop_size: 1.0
  center: false

name: openl3_${.encoder.input_repr}_${.encoder.content_type}_${.encoder.embedding_size}_h=${.encoder.hop_size}_c=${.encoder.center}
group: openl3